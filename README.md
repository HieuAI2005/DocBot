# ğŸ¤– DocBot - AI-Powered Document Q&A System

An intelligent chatbot system that enables natural conversations with your PDF documents using advanced AI technologies including RAG (Retrieval-Augmented Generation) and SLM reasoning.

![Version](https://img.shields.io/badge/version-1.0.0-blue)
![Python](https://img.shields.io/badge/python-3.10-green)
![Node](https://img.shields.io/badge/node-20.x-green)
![License](https://img.shields.io/badge/license-MIT-blue)

---

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Architecture](#-architecture)
- [AI Pipeline](#-ai-pipeline)
- [Tech Stack](#-tech-stack)
- [Installation](#-installation)
- [Usage](#-usage)
- [Project Structure](#-project-structure)

---

## âœ¨ Features

### Core Capabilities
- ğŸ“„ **PDF Document Upload** - Support for multiple PDF files with intelligent extraction
- ğŸ’¬ **Natural Language Chat** - ChatGPT-style conversational interface
- ğŸ§  **AI Reasoning Display** - Transparent thought process visualization
- ğŸ¯ **Context-Aware Responses** - Answers based on document content
- ğŸŒ **Bilingual Support** - Vietnamese and English responses
- ğŸ“Š **Document Management** - Easy upload, view, and delete operations

### Advanced Features
- ğŸ” **Adaptive RAG** - Hybrid BM25 + Dense retrieval with dynamic re-ranking
- ğŸ’¡ **Chain-of-Thought** - Step-by-step reasoning before final answers
- ğŸ¨ **Modern UI** - Dark theme with green accents and smooth animations
- âš¡ **Real-time Streaming** - Token-by-token response generation
- ğŸ“± **Responsive Design** - Works on desktop, tablet, and mobile

---

## ğŸ— Architecture

### System Overview

```mermaid
graph TB
    subgraph "Frontend (React + Vite)"
        UI[User Interface]
        Sidebar[Document Sidebar]
        Chat[Chat Interface]
        PDF[PDF Viewer]
    end
    
    subgraph "Backend (FastAPI)"
        API[REST API]
        Upload[Upload Service]
        ChatSvc[Chat Service]
        DocSvc[Document Service]
    end
    
    subgraph "AI Pipeline"
        Extract[PDF Extraction]
        RAG[Adaptive RAG]
        SLM[SLM Engine]
        
        subgraph "RAG Components"
            BM25[BM25 Retrieval]
            Dense[Dense Retrieval]
            Rerank[Re-ranking]
        end
    end
    
    subgraph "Storage"
        DB[(SQLite Database)]
        Files[File Storage]
        Index[Vector Index]
    end
    
    UI --> API
    Sidebar --> API
    Chat --> API
    PDF --> Files
    
    API --> Upload
    API --> ChatSvc
    API --> DocSvc
    
    Upload --> Extract
    Extract --> RAG
    ChatSvc --> RAG
    ChatSvc --> SLM
    
    RAG --> BM25
    RAG --> Dense
    BM25 --> Rerank
    Dense --> Rerank
    
    DocSvc --> DB
    Upload --> DB
    Upload --> Files
    RAG --> Index
```

### Request Flow

```mermaid
sequenceDiagram
    participant User
    participant Frontend
    participant API
    participant RAG
    participant SLM
    participant DB

    User->>Frontend: Upload PDF
    Frontend->>API: POST /api/documents/upload
    API->>DB: Save metadata
    API->>RAG: Extract & Index
    RAG->>DB: Store chunks
    API-->>Frontend: Upload complete

    User->>Frontend: Ask question
    Frontend->>API: POST /api/chat (streaming)
    API->>DB: Get conversation history
    API->>RAG: Retrieve relevant chunks
    RAG-->>API: Return top-k chunks
    API->>SLM: Generate with context
    
    loop Streaming
        LLM-->>API: Token
        API-->>Frontend: SSE event
        Frontend-->>User: Display token
    end
    
    API->>DB: Save message
    API-->>Frontend: Stream complete
```

---

## ğŸ¤– AI Pipeline

### 1. Document Processing

```
PDF Document
    â†“
[PyPDF2 Extraction]
    â†“
Raw Text
    â†“
[Smart Chunking]
  - Chunk size: 1200 chars
  - Stride: 200 chars
    â†“
Text Chunks
```

### 2. Adaptive RAG System

```mermaid
graph LR
    Query[User Query] --> Expand[Query Expansion]
    Expand --> BM25[BM25 Retrieval<br/>Keyword-based]
    Expand --> Dense[Dense Retrieval<br/>E5-multilingual]
    
    BM25 --> Combine[Score Normalization<br/>& Combination]
    Dense --> Combine
    
    Combine --> Filter{Document<br/>Filter?}
    Filter -->|Yes| DocFilter[Filter by doc_id]
    Filter -->|No| Rerank[Feedback Re-ranking]
    DocFilter --> Rerank
    
    Rerank --> TopK[Top-K Selection]
    TopK --> Context[Context for SLM]
```

**Key Components:**
- **BM25**: Sparse retrieval using keyword matching
- **Dense Retrieval**: Semantic search using `multilingual-e5-small` embeddings
- **FAISS Index**: Fast similarity search for dense vectors
- **Feedback Learning**: User feedback improves future retrievals
- **Dynamic Top-K**: Adaptive number of chunks based on query

### 3. SLM Generation

```
Context Chunks
    â†“
[Prompt Construction]
  - System: Instructions in Vietnamese
  - Context: Retrieved chunks
  - History: Last 3 messages
  - Query: User question
    â†“
[Qwen2.5-1.5B-Instruct]
  - Chain-of-Thought prompting
  - Structured output (reasoning + answer)
    â†“
[Streaming Parser]
  - Extract <reasoning>...</reasoning>
  - Extract <answer>...</answer>
    â†“
Real-time Display
```

**LLM Features:**
- **Model**: Qwen2.5-1.5B-Instruct (1.5 billion parameters)
- **Precision**: FP16 on GPU / FP32 on CPU
- **Context**: Up to 4096 tokens
- **Output**: Max 256 tokens with streaming
- **Temperature**: 0.7 for balanced creativity/accuracy

---

## ğŸ›  Tech Stack

### Frontend
- **Framework**: React 18 with Vite
- **Styling**: Vanilla CSS with custom design system
- **PDF Rendering**: react-pdf
- **Markdown**: react-markdown + remark-gfm
- **Icons**: lucide-react
- **Code Highlighting**: react-syntax-highlighter

### Backend
- **Framework**: FastAPI (Python 3.10)
- **Database**: SQLAlchemy with SQLite
- **LLM Engine**: Hugging Face Transformers
- **Vector Store**: FAISS
- **Text Retrieval**: rank-bm25
- **Embeddings**: sentence-transformers
- **PDF Processing**: PyPDF2 (fallback: mineru)

### AI/ML
- **SLM**: Qwen2.5-1.5B-Instruct
- **Embeddings**: intfloat/multilingual-e5-small
- **Retrieval**: Hybrid BM25 + Dense
- **Framework**: PyTorch + Transformers

---

## ğŸš€ Installation

### Prerequisites
- Python 3.10+
- Node.js 20.x+
- CUDA-capable GPU (optional, recommended)
- 8GB+ RAM

### Quick Start

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/DocBot.git
cd DocBot
```

2. **Setup Python environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

3. **Install Node dependencies**
```bash
cd frontend
npm install
cd ..
```

4. **Run the application**
```bash
bash start.sh
```

The application will be available at:
- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

---

## ğŸ“– Usage

### 1. Upload Documents
- Click **"Upload PDF"** button in sidebar
- Select PDF file(s) to upload
- Wait for processing and indexing

### 2. Chat Modes

**Document-Specific Chat:**
- Click on a document in the sidebar
- Ask questions about that specific document
- Bot retrieves context only from selected document

**Global Chat:**
- Click on **"DocBot"** logo
- Ask questions across all uploaded documents
- Bot searches in entire knowledge base

### 3. View AI Reasoning
- Click the **lightbulb icon** on bot messages
- Expand to see step-by-step reasoning
- Understand how the bot arrived at the answer

### 4. Manage Documents
- **View**: Click on document to open PDF viewer
- **Delete**: Click trash icon to remove document
- **Refresh**: Documents auto-update on changes

---

## ğŸ“ Project Structure

```
DocBot/
â”œâ”€â”€ backend/                    # FastAPI backend
â”‚   â”œâ”€â”€ app.py                 # Main application entry
â”‚   â”œâ”€â”€ config.py              # Backend configuration
â”‚   â”œâ”€â”€ models/                # Database models & schemas
â”‚   â”‚   â”œâ”€â”€ database.py        # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ schemas.py         # Pydantic schemas
â”‚   â”‚   â””â”€â”€ db_manager.py      # Database utilities
â”‚   â”œâ”€â”€ routers/               # API endpoints
â”‚   â”‚   â”œâ”€â”€ upload.py          # Document upload
â”‚   â”‚   â”œâ”€â”€ chat.py            # Chat endpoints
â”‚   â”‚   â”œâ”€â”€ qa.py              # Q&A endpoints
â”‚   â”‚   â””â”€â”€ admin.py           # Admin utilities
â”‚   â”œâ”€â”€ services/              # Business logic
â”‚   â”‚   â”œâ”€â”€ chat_service.py    # LLM generation
â”‚   â”‚   â”œâ”€â”€ adaptive_rag.py    # RAG system
â”‚   â”‚   â””â”€â”€ document_service.py
â”‚   â””â”€â”€ process/               # Document processing
â”‚       â”œâ”€â”€ config.py          # Processing config
â”‚       â””â”€â”€ extract/           # PDF extraction
â”‚           â””â”€â”€ mineru.py      # Advanced extraction
â”œâ”€â”€ frontend/                  # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ Sidebar.jsx    # Document sidebar
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Message.jsx    # Message display
â”‚   â”‚   â”‚   â”œâ”€â”€ DocumentViewer.jsx
â”‚   â”‚   â”‚   â””â”€â”€ MessageInput.jsx
â”‚   â”‚   â”œâ”€â”€ services/          # API clients
â”‚   â”‚   â”‚   â””â”€â”€ api.js         # API service
â”‚   â”‚   â”œâ”€â”€ App.jsx            # Main app component
â”‚   â”‚   â””â”€â”€ index.css          # Global styles
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ data/                      # Data storage
â”‚   â”œâ”€â”€ uploads/              # Uploaded PDFs
â”‚   â”œâ”€â”€ vector_store/         # FAISS indices
â”‚   â””â”€â”€ docbot.db             # SQLite database
â”œâ”€â”€ start.sh                   # Startup script
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                 # This file
```

---

## ğŸ”§ Configuration

### Backend Config (`backend/process/config.py`)

```python
# LLM Settings
LLM = "Qwen/Qwen2.5-1.5B-Instruct"
MAX_CONTEXT_CHARS = 2500

# RAG Settings
CHUNK_CHARS = 1200
CHUNK_STRIDE = 200
TOPK_BM25 = 8
TOPK_EMB = 8
KEEP_TOPK = 6

# Embedding Model
EMB_MODEL = "intfloat/multilingual-e5-small"
```

### Environment Variables

Create `.env` file:
```env
# Optional settings
CUDA_VISIBLE_DEVICES=0  # GPU selection
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
```

---

## ğŸ¯ Features Roadmap

- [x] PDF document upload and processing
- [x] Adaptive RAG with hybrid retrieval
- [x] Chain-of-thought reasoning
- [x] Streaming responses
- [x] Document-specific and global chat
- [x] Vietnamese language support
- [ ] Multi-document comparison
- [ ] Export chat history
- [ ] Advanced analytics dashboard
- [ ] Multi-user support
- [ ] Cloud deployment

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ‘¨â€ğŸ’» Author

**Duong Hieu**
- GitHub: [@HieuAI2005](https://github.com/HieuAI2005)
- Email: hieuai0305@gmail.com

---

## ğŸ™ Acknowledgments

- Qwen Team for the excellent LLM models
- Hugging Face for the Transformers library
- FastAPI and React communities
- All open-source contributors

---
